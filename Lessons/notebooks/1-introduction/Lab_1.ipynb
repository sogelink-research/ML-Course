{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "\n",
    "## Datasets\n",
    "\n",
    "For this lab, we will use the three following datasets:\n",
    "\n",
    "- Iris plants dataset `sklearn.datasets.load_iris`\n",
    "- Optical recognition of handwritten digits dataset `sklearn.datasets.load_digits`\n",
    "- Breast cancer wisconsin (diagnostic) dataset `sklearn.datasets.load_breast_cancer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, fetch_california_housing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import plot_confusion_matrix, plot_evaluation, plot_decision_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = load_iris()\n",
    "X, y, feature_names, class_names = (\n",
    "    data.data,\n",
    "    data.target,\n",
    "    data.feature_names,\n",
    "    data.target_names,\n",
    ")\n",
    "\n",
    "print(f\"{feature_names = }\")\n",
    "print(f\"{class_names = }\")\n",
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"species\"] = [class_names[i] for i in y]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    df,\n",
    "    hue=\"species\",\n",
    "    palette=\"Set2\",\n",
    "    diag_kind=\"kde\",\n",
    "    markers=[\"o\", \"s\", \"D\"],\n",
    "    height=2.5,\n",
    "    aspect=1,\n",
    "    plot_kws=dict(s=20),\n",
    ")\n",
    "plt.suptitle(\"Pairwise features\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into a training set and a testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "print(f\"{X_train.shape = }\")\n",
    "print(f\"{X_test.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and fit/train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0)  # random_state=0 for reproducibility\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, class_names)\n",
    "plot_evaluation(y_test, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "Accuracy measures the proportion of **correctly classified instances** (both true positives and true negatives) out of the total instances.\n",
    "\n",
    "Where:\n",
    "\n",
    "- $TP$ = True Positives\n",
    "- $TN$ = True Negatives\n",
    "- $FP$ = False Positives\n",
    "- $FN$ = False Negatives\n",
    "\n",
    "#### Precision\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "Precision measures the proportion of **true positive instances** out of the instances that were **predicted as positive**. It indicates how many of the predicted positives are actually positive.\n",
    "\n",
    "#### Recall\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Recall measures the proportion of **true positive instances** out of the **actual positive instances**. It indicates how many of the actual positives were correctly identified.\n",
    "\n",
    "#### F1-Score\n",
    "\n",
    "$$\n",
    "\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "The F1-Score is the **harmonic mean** of **precision and recall**. It provides a single metric that balances both precision and recall, especially useful when you need to account for both false positives and false negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two features only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_evaluate_iris(\n",
    "    model, features_used: tuple[int, int], normalize: bool = True\n",
    "):\n",
    "    data, _ = load_iris()\n",
    "    X, y, feature_names, class_names = (\n",
    "        data.data[:, features_used],\n",
    "        data.target,\n",
    "        [data.feature_names[i] for i in features_used],\n",
    "        data.target_names,\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.5, random_state=0\n",
    "    )\n",
    "\n",
    "    if normalize:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(24, 5))\n",
    "    plt.suptitle(\n",
    "        f\"{model.__class__.__name__} using features={features_used} and normalization={normalize}\"\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(y_test, y_pred, class_names, ax=axs[0])\n",
    "    plot_evaluation(y_test, y_pred, class_names, ax=axs[1])\n",
    "    plot_decision_boundaries(model, X_train, y_train, feature_names, ax=axs[2])\n",
    "    axs[2].set_title(axs[2].get_title() + \" (Training Data)\")\n",
    "    plot_decision_boundaries(model, X_test, y_test, feature_names, ax=axs[3])\n",
    "    axs[3].set_title(axs[3].get_title() + \" (Testing Data)\")\n",
    "\n",
    "\n",
    "model.__class__.__name__\n",
    "fit_predict_evaluate_iris(LogisticRegression(random_state=0), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_evaluate_iris(LogisticRegression(random_state=0), (2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_evaluate_iris(LogisticRegression(random_state=0), (2, 3), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_evaluate_iris(KNeighborsClassifier(n_neighbors=5), (2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_evaluate_iris(KNeighborsClassifier(n_neighbors=5), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_evaluate_iris(KNeighborsClassifier(n_neighbors=5), (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_evaluate_iris(\n",
    "    SVC(kernel=\"poly\"),\n",
    "    (0, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_evaluate_iris(\n",
    "    SVC(kernel=\"poly\", degree=10),\n",
    "    (0, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_evaluate_iris(SVC(kernel=\"rbf\"), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_evaluate_iris(\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0), (0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California Housing dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()\n",
    "X, y, classes = data.data, data.target, data.feature_names\n",
    "print(X.shape, y.shape, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "print(train_data.data.shape, train_data.targets.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
