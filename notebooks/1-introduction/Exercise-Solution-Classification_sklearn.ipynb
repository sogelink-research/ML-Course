{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "This notebook serves as a playground to experiment with the `sklearn` library to use classic machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Your objective here is to achieve the best performance possible on a **subset of [Fashion MNIST](https://openml.org/search?type=data&status=active&id=40996)** by exploring models and their parameters. This dataset is a more complex version of MNIST, with 10 classes of clothes instead of digits. Each sample is a 28x28 grayscale image, which is flattened into a 784-dimensional vector. To reduce the fitting time of the models, we will use only the **2000 first samples** of the dataset to evaluate the methods and train the models. A random part of the rest of the dataset will then be used to evaluate the final model and determine who found the best model. The metric used to compare the models will be the **accuracy**.\n",
    "\n",
    "This is the main part of the notebook. However, you are **free to explore other things** if you are curious. Here is a non-exhaustive list of things you could try:\n",
    "\n",
    "- Use different datasets (a few ideas can be found in [Other datasets](#other-datasets))\n",
    "- Make visualizations of the data\n",
    "- Make visualizations of the errors of the models\n",
    "- Make an analysis of the errors of the models\n",
    "- Use other metrics to compare the models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "Here are a few tips related to finding the best model:\n",
    "\n",
    "- A list of all the sklearn algorithms for supervised learning can be found [here](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "- The most common way to evaluate models is [cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html). You can directly use [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) to perform cross-validation on a given model.\n",
    "- You can also use [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to search for the best combinations of parameters. This will perform cross-validation with all the combinations of parameters to find the solution yielding the best results. You can look [here](https://scikit-learn.org/stable/api/sklearn.model_selection.html#hyper-parameter-optimizers) for other hyper-parameters optimizers.\n",
    "- Other methods related to cross-validation and hyper-parameters tuning can be found in the [`model_selection` module](https://scikit-learn.org/stable/api/sklearn.model_selection.html#splitters)\n",
    "\n",
    "A few other tips:\n",
    "\n",
    "- Depending on your preferences, you can use `pandas` or `numpy` to manipulate the data. `pandas` is more high-level and is often easier to use, but `numpy` is more efficient.\n",
    "- To make visualizations, you can use `matplotlib` or `seaborn`. `seaborn` is more high-level and allows to make nice visualizations easily for data-related topics. `matplotlib` is more flexible and allows to make more complex visualizations. `matplotlib` can also be used to visualize images like the ones in this dataset.\n",
    "- To learn about the different metrics available in `sklearn`, you can look at this quite exhaustive [article of the user guide](https://scikit-learn.org/stable/modules/model_evaluation.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Fashion-MNIST\"\n",
    "dataset = fetch_openml(dataset_name, version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the first 2000 samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_samples = 2000\n",
    "\n",
    "X: np.ndarray = dataset.data[:used_samples].to_numpy()\n",
    "y: np.ndarray = dataset.target[:used_samples].to_numpy()\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "labels, counts = np.unique(y, return_counts=True)\n",
    "df = pd.DataFrame(\n",
    "    {\"Class Name\": [CLASS_NAMES[int(label)] for label in labels], \"Count\": counts}\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display what the dataset looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image_data: pd.DataFrame | np.ndarray, label: int) -> None:\n",
    "    if isinstance(image_data, pd.Series):\n",
    "        image = image_data.to_numpy().reshape(28, 28)\n",
    "    elif isinstance(image_data, np.ndarray):\n",
    "        image = image_data.reshape(28, 28)\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            f\"image_data must be a pandas DataFrame or a numpy array, not {type(image_data)}\"\n",
    "        )\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.colorbar(label=\"Pixel Value\")\n",
    "    plt.title(CLASS_NAMES[label])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "index = 3\n",
    "plot_image(X[index], int(y[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from typing import Any, Dict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def test_method(\n",
    "    classifier_class,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    parameters_grid: Dict[str, Any],\n",
    "    scale: bool,\n",
    "):\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    # Set a fixed cross-validation strategy for reproducibility\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Exhaustive search for the best hyperparameters\n",
    "    search = GridSearchCV(\n",
    "        classifier_class,\n",
    "        parameters_grid,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "\n",
    "    print(f\"Best parameters: {search.best_params_}\")\n",
    "    print(f\"Best score: {search.best_score_}\")\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# method = RandomForestClassifier()\n",
    "# parameters = {\n",
    "#     \"n_estimators\": [10, 20, 100, 200, 500],\n",
    "#     \"max_depth\": [None, 10, 20, 100, 200, 500],\n",
    "#     \"max_features\": [\"sqrt\", \"log2\"],\n",
    "# }\n",
    "method = SVC()\n",
    "parameters = {\n",
    "    \"C\": [1, 3, 10, 20, 50, 100],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"gamma\": [\"scale\", 0.0001, 0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "search = test_method(method, X, y, parameters, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "search_df = pd.DataFrame(search.cv_results_)\n",
    "file_name = f\"results_{method.__class__.__name__}_0.csv\"\n",
    "while path.exists(file_name):\n",
    "    file_name_number = int(file_name.split(\"_\")[-1].split(\".\")[0])\n",
    "    file_name_number += 1\n",
    "    file_name = f\"results_{method.__class__.__name__}_{file_name_number}.csv\"\n",
    "search_df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other datasets\n",
    "\n",
    "sklearn provides several various datasets that we can use to experiment on the performance of different models, with various complexities and sizes. They can be found [here](https://scikit-learn.org/stable/api/sklearn.datasets.html). The datasets of interest for us are the following:\n",
    "\n",
    "| Name                      | Link                                                                                                                                            | Targets            | Features | Dimensionality | Samples |\n",
    "| ------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- | ------------------ | -------- | -------------- | ------- |\n",
    "| Breast Cancer Wisconsin   | [`sklearn.datasets.load_breast_cancer`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)             | Classification (2) | Real     | 30             | 569     |\n",
    "| Wine Quality              | [`sklearn.datasets.load_wine`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)                               | Classification (3) | Real     | 13             | 178     |\n",
    "| California Housing Prices | [`sklearn.datasets.fetch_california_housing`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) | Regression         | Real     | 8              | 20640   |\n",
    "\n",
    "If you are really interested in image processing, there also exist many variations of MNIST that introduce more complexity:\n",
    "\n",
    "| Name                                                                                    | Specificity                         | Classes | Features Type  | Dimensionality | Samples               |\n",
    "| --------------------------------------------------------------------------------------- | ----------------------------------- | ------- | -------------- | -------------- | --------------------- |\n",
    "| [MNIST](https://openml.org/search?type=data&status=active&id=554)                       | N/A                                 | 10      | Integers 0-255 | 784 (28×28)    | 70000 (60000 + 10000) |\n",
    "| [Fashion MNIST](https://openml.org/search?type=data&status=active&id=40996)             | Clothes                             | 10      | Integers 0-255 | 784 (28×28)    | 70000 (60000 + 10000) |\n",
    "| [KMNIST](https://openml.org/search?type=data&status=active&id=41982)                    | Japanese characters                 | 10      | Integers 0-255 | 784 (28×28)    | 70000 (60000 + 10000) |\n",
    "| [EMNIST Balanced](https://openml.org/search?type=data&status=active&id=41039)           | Digits and letters                  | 47      | Integers 0-255 | 784 (28×28)    | 131600                |\n",
    "| [QMNIST](https://github.com/facebookresearch/qmnist)                                    | Higher quality with improved labels | 10      | Integers 0-255 | 784 (28×28)    | 60000                 |\n",
    "| [NotMNIST](https://huggingface.co/datasets/anubhavmaity/notMNIST)                       | Letters a-j with various fonts      | 10      | Integers 0-255 | 784 (28×28)    | 529114                |\n",
    "| [MNIST-C](https://github.com/google-research/mnist-c)                                   | Various types of corruptions        | 10      | Integers 0-255 | 784 (28×28)    | 60000                 |\n",
    "| [Sign Language MNIST](https://openml.org/search?type=data&status=active&id=45082)       | Sign language                       | 24      | Integers 0-255 | 784 (28×28)    | 34627 (27455 + 7172)  |\n",
    "| [Street View House Numbers](https://openml.org/search?type=data&status=active&id=41081) | House numbers                       | 10      | Integers 0-255 | 3072 (32×32×3) | 99289                 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
