{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.adam import Adam\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import plot_full_evaluation, create_activation_image\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using gpu: %s \" % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_function = datasets.MNIST\n",
    "# datasets_function = datasets.FashionMNIST\n",
    "# datasets_function = datasets.CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transform to scale images to [0, 1]\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224))])\n",
    "\n",
    "try:  # Load the dataset with the transform\n",
    "    train_dataset = datasets_function(\n",
    "        root=\"./data\", train=True, transform=transform, download=True\n",
    "    )\n",
    "    test_dataset = datasets_function(\n",
    "        root=\"./data\", train=False, transform=transform, download=True\n",
    "    )\n",
    "except TypeError:\n",
    "    train_dataset = datasets_function(\n",
    "        root=\"./data\", image_set=\"train\", transform=transform, download=True\n",
    "    )\n",
    "    test_dataset = datasets_function(\n",
    "        root=\"./data\", image_set=\"val\", transform=transform, download=True\n",
    "    )\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Verify the scaling\n",
    "for data, _ in train_loader:\n",
    "    print(\"Min pixel value:\", data.min().item())\n",
    "    print(\"Max pixel value:\", data.max().item())\n",
    "    break  # Check only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute mean and standard deviation\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "# train_dataset = datasets_function(\n",
    "#     root=\"./data\", train=True, transform=transform, download=True\n",
    "# )\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# sum_tensor = torch.zeros(1)\n",
    "# sum_squared_tensor = torch.zeros(1)\n",
    "# count = 0\n",
    "\n",
    "# for data, _ in train_loader:\n",
    "#     sum_tensor += data.sum()\n",
    "#     sum_squared_tensor += (data**2).sum()\n",
    "#     count += data.numel()\n",
    "\n",
    "# mean = sum_tensor / count\n",
    "# std = torch.sqrt(sum_squared_tensor / count - mean**2)\n",
    "\n",
    "# print(\"Mean:\", mean.item())\n",
    "# print(\"Standard Deviation:\", std.item())\n",
    "\n",
    "# # Create normalization transform\n",
    "# normalize_transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(\n",
    "#             mean=[mean.item()], std=[std.item()]\n",
    "#         ),  # Normalize to mean 0 and std 1\n",
    "#         transforms.Normalize(mean=[-1], std=[2]),  # Scale to mean 0.5 and std 0.5\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Apply the Normalization Transform to the Dataset\n",
    "# train_dataset = datasets_function(\n",
    "#     root=\"./data\", train=True, transform=normalize_transform, download=True\n",
    "# )\n",
    "# test_dataset = datasets_function(\n",
    "#     root=\"./data\", train=False, transform=normalize_transform, download=True\n",
    "# )\n",
    "\n",
    "# # Verify the transform\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "# for data, _ in train_loader:\n",
    "#     print(\"Transformed Mean:\", data.mean().item())\n",
    "#     print(\"Transformed Std:\", data.std().item())\n",
    "#     break  # Check only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = 0.5\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"{class_names = }\")\n",
    "print(f\"{num_classes = }\")\n",
    "\n",
    "# Calculate the number of samples for the subsets\n",
    "num_train_samples = int(len(train_dataset) * proportion)\n",
    "num_test_samples = int(len(test_dataset) * proportion)\n",
    "\n",
    "# Create subsets of the datasets\n",
    "train_subset = Subset(train_dataset, range(num_train_samples))\n",
    "test_subset = Subset(test_dataset, range(num_test_samples))\n",
    "\n",
    "train_data_size = len(train_subset)\n",
    "test_data_size = len(test_subset)\n",
    "input_shape = train_subset[0][0].shape\n",
    "input_size = np.prod(input_shape)\n",
    "print(f\"{train_data_size = }\")\n",
    "print(f\"{test_data_size = }\")\n",
    "print(f\"{input_shape = }\")\n",
    "print(f\"{input_size = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(dataset, class_names, num_instances=3):\n",
    "    # Initialize a dictionary to store instances for each class\n",
    "    instances = {class_name: [] for class_name in class_names}\n",
    "\n",
    "    # Iterate through the dataset and collect instances\n",
    "    for img, label in dataset:\n",
    "        class_name = class_names[label]\n",
    "        if len(instances[class_name]) < num_instances:\n",
    "            instances[class_name].append(img)\n",
    "        if all(\n",
    "            len(instances[class_name]) == num_instances for class_name in class_names\n",
    "        ):\n",
    "            break\n",
    "\n",
    "    # Create a grid of subplots\n",
    "    fig, axes = plt.subplots(\n",
    "        num_instances,\n",
    "        len(class_names),\n",
    "        figsize=(len(class_names) * 2, num_instances * 2),\n",
    "    )\n",
    "\n",
    "    # Plot the collected instances\n",
    "    for i in range(num_instances):\n",
    "        for j, class_name in enumerate(class_names):\n",
    "            ax = axes[i, j]\n",
    "            cmap = \"gray\" if input_shape[0] == 1 else None\n",
    "            ax.imshow(instances[class_name][i].permute(1, 2, 0), cmap=cmap)\n",
    "            ax.axis(\"off\")\n",
    "            if i == 0:\n",
    "                ax.set_title(class_name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_instances(train_subset, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training\n",
    "\n",
    "train_loader = DataLoader(dataset=train_subset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_subset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, num_classes: int, input_shape: tuple[int, int, int]):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.input_channels = input_shape[0]\n",
    "        self.input_width = input_shape[1]\n",
    "        self.input_size = self.input_channels * (self.input_width) ** 2\n",
    "        self.linear_input_width = self.input_width // 8\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(input_shape[0], 32, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Flatten(1, -1),\n",
    "                # nn.Dropout(),\n",
    "                # nn.Linear(64 * 7 * 7, 64),\n",
    "                # nn.ReLU(),\n",
    "                # nn.Dropout(),\n",
    "                # nn.Linear(64, num_classes),\n",
    "                nn.Linear(128 * (self.linear_input_width) ** 2, num_classes),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleNN(num_classes=len(class_names), input_shape=input_shape).to(device)\n",
    "tensor = torch.rand(1, *input_shape).to(device)\n",
    "model(tensor)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    num_epochs: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: Optimizer,\n",
    "):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1:>{len(str(num_epochs))}}/{num_epochs}], Loss: {running_loss/len(train_loader):2.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Evaluation on the test set\n",
    "def evaluate_model(model: nn.Module, test_loader: DataLoader, class_names: list[str]):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true.extend(list(labels.cpu().numpy()))\n",
    "            y_pred.extend(list(predicted.cpu().numpy()))\n",
    "\n",
    "    plot_full_evaluation(np.array(y_true), np.array(y_pred), class_names)\n",
    "\n",
    "\n",
    "# # 6. Plot some predictions\n",
    "# def plot_predictions(model, test_loader, classes):\n",
    "#     model.eval()\n",
    "#     images, labels = next(iter(test_loader))\n",
    "#     images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#     outputs = model(images)\n",
    "#     _, preds = torch.max(outputs, 1)\n",
    "\n",
    "#     # Plot the first 6 test images and their predictions\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     for i in range(6):\n",
    "#         plt.subplot(2, 3, i + 1)\n",
    "#         plt.imshow(images[i].cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "#         plt.title(f\"True: {classes[labels[i]]}, Pred: {classes[preds[i]]}\")\n",
    "#         plt.axis(\"off\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # Plot predictions\n",
    "# plot_predictions(model, test_loader, test_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration (Use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10  # Number of epochs\n",
    "learning_rate = 0.001  # Learning rate for optimizer\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleNN(num_classes=num_classes, input_shape=input_shape).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)  # Often used optimizer\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, num_epochs, criterion, optimizer)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [len(model.layers) - 1]\n",
    "channels = list(range(num_classes))\n",
    "channels_names = class_names\n",
    "steps = 200\n",
    "lr = 0.01\n",
    "show_steps = True\n",
    "\n",
    "activation_images_transform = None\n",
    "# activation_images_transform = transforms.Compose(\n",
    "#     [\n",
    "# transforms.Lambda(lambda x: x + 0.001 * (2 * torch.rand_like(x) - 1)),\n",
    "# transforms.RandomAffine(degrees=5, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "# transforms.RandomCrop(20),\n",
    "# transforms.ElasticTransform(alpha=50.0),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Compute the activation images\n",
    "activation_images = np.zeros((len(layers), len(channels), *input_shape))\n",
    "for i, layer in enumerate(tqdm(layers, position=0, desc=\"layer\", colour=\"green\")):\n",
    "    for j, channel in enumerate(\n",
    "        tqdm(channels, position=1, desc=\"channel\", colour=\"red\")\n",
    "    ):\n",
    "        activation_images[i, j] = create_activation_image(\n",
    "            model=model,\n",
    "            layer=layer,\n",
    "            channel=channel,\n",
    "            input_mean=0,\n",
    "            input_std=1,\n",
    "            steps=steps,\n",
    "            lr=lr,\n",
    "            show_steps=show_steps,\n",
    "            transform=activation_images_transform,\n",
    "            input_shape=input_shape,\n",
    "            progress_bar=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the images\n",
    "for i, layer in enumerate(layers):\n",
    "    instances = len(channels)\n",
    "    cols = int(np.ceil(np.sqrt(instances)))\n",
    "    rows = int(np.ceil(instances / cols))\n",
    "    plt.figure(figsize=(15, 15 * rows / cols))\n",
    "    plt.suptitle(f\"Layer {layer}\")\n",
    "    for j, (channel, channel_name) in enumerate(zip(channels, channels_names)):\n",
    "        plt.subplot(rows, cols, j + 1)\n",
    "        plt.imshow(activation_images[i, j].transpose(1, 2, 0).squeeze(), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(channel_name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
