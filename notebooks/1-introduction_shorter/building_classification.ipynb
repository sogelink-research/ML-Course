{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify buildings from DSM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary stuff for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary files if running in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    import urllib.request\n",
    "    import zipfile\n",
    "    from pathlib import Path\n",
    "    from shutil import copy, copytree, rmtree\n",
    "\n",
    "    # Download the GitHub repository\n",
    "    zip_path = Path(\"simple_model.zip\")\n",
    "    directory_path = Path(\".\")\n",
    "    initial_simple_model_path = Path(\n",
    "        \"ML-Course-main/notebooks/1-introduction_shorter/simple_model\"\n",
    "    )\n",
    "    simple_model_path = Path(\"simple_model\")\n",
    "\n",
    "    url = \"https://github.com/sogelink-research/ML-Course/archive/refs/heads/main.zip\"\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "\n",
    "    # Unzip the repository\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(directory_path)\n",
    "\n",
    "    # Take the files from the simple model\n",
    "    copytree(\n",
    "        initial_simple_model_path,\n",
    "        simple_model_path,\n",
    "        copy_function=lambda s, d: not Path(d).exists() and copy(s, d),\n",
    "        dirs_exist_ok=True,\n",
    "    )\n",
    "\n",
    "    # Take the requirements\n",
    "    initial_requirements_path = Path(\n",
    "        \"ML-Course-main/notebooks/1-introduction_shorter/requirements.txt\"\n",
    "    )\n",
    "    requirements_path = Path(\"requirements.txt\")\n",
    "    copy(initial_requirements_path, requirements_path)\n",
    "\n",
    "    # Clean the rest\n",
    "    zip_path.unlink()\n",
    "    rmtree(Path(\"ML-Course-main\"))\n",
    "\n",
    "    def get_files(path: Path, extensions: list[str]):\n",
    "        all_files = []\n",
    "        for ext in extensions:\n",
    "            all_files.extend(path.glob(f\"*.{ext}\"))\n",
    "        return all_files\n",
    "\n",
    "    for file_path in get_files(directory_path, [\"py\", \"just\"]):\n",
    "        file_path.unlink()\n",
    "\n",
    "    print(\"Downloaded the necessary files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary packages if running in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def get_new_model_name() -> str:\n",
    "    return datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from simple_model.dataloader import ImagesLoader\n",
    "from simple_model.nn import SegmentationConvolutionalNetwork\n",
    "from simple_model.dataparse import download_all\n",
    "from simple_model.bbox import BboxInt\n",
    "import torch\n",
    "\n",
    "minx, maxy, maxx, miny = 120000, 487000, 125000, 482000\n",
    "bbox = BboxInt(minx, maxy, maxx, miny, True)\n",
    "image_size = 512\n",
    "filter_buildings = True\n",
    "main_data_folder = Path(\"data\")\n",
    "main_models_folder = Path(\"models\")\n",
    "\n",
    "main_data_folder.mkdir(parents=True, exist_ok=True)\n",
    "main_models_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_folder, images_path, masks_path = download_all(\n",
    "    bbox, main_data_folder, image_size, filter_buildings\n",
    ")\n",
    "\n",
    "image_shape = (image_size, image_size)\n",
    "nodata = 0\n",
    "\n",
    "images_loader = ImagesLoader(image_shape=image_shape, nodata=nodata)\n",
    "images_loader.load_data(images_path, masks_path)\n",
    "dataloaders = images_loader.get_dataloaders(batch_size=8, train_proportion=0.8)\n",
    "\n",
    "model_name = get_new_model_name()\n",
    "model_folder = main_models_folder / model_name\n",
    "model_folder.mkdir(parents=True, exist_ok=True)\n",
    "model = SegmentationConvolutionalNetwork(\n",
    "    image_size=image_shape,\n",
    "    encoder_channels=[16, 32, 64],\n",
    "    layers_downsample=2,\n",
    "    layers_upsample=2,\n",
    "    input_channels=1,\n",
    "    model_folder=model_folder,\n",
    "    data_folders=[data_folder],\n",
    ")\n",
    "\n",
    "# Better speed for CPU\n",
    "torch.compile(model)\n",
    "\n",
    "visualisation_output = model_folder / \"visualisation\" / \"output.png\"\n",
    "model.train_model(\n",
    "    dataloaders=dataloaders,\n",
    "    epochs=200,\n",
    "    visualisation_output=visualisation_output,\n",
    "    stop_early_after=20,\n",
    ")\n",
    "\n",
    "output_folder = model_folder / \"output\"\n",
    "model.save_predictions(\n",
    "    images_loader=images_loader,\n",
    "    dataloaders=dataloaders,\n",
    "    output_folder=output_folder,\n",
    ")\n",
    "metrics_folder = model_folder / \"metrics\"\n",
    "model.save_metrics(\n",
    "    images_loader=images_loader,\n",
    "    dataloaders=dataloaders,\n",
    "    metrics_folder=metrics_folder,\n",
    ")\n",
    "model.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = SegmentationConvolutionalNetwork.load_model(model_folder)\n",
    "# model2.save_predictions(\n",
    "#     images_loader=images_loader,\n",
    "#     dataloaders=dataloaders,\n",
    "#     output_folder=output_folder,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
